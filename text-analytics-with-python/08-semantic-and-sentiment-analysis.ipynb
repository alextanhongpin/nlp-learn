{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordNet\n",
    "\n",
    "WordNet is a huge database for the english language.\n",
    "\n",
    "## Synsets\n",
    "\n",
    "Synset is a collection or set of data entities that are considered to be semantically similar.\n",
    "\n",
    "## Repo\n",
    "https://github.com/dipanjanS/text-analytics-with-python/tree/master/Old-First-Edition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Synsets: 5\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd\n",
    "\n",
    "term = 'fruit'\n",
    "synsets = wn.synsets(term)\n",
    "print('Total Synsets:', len(synsets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset: Synset('fruit.n.01')\n",
      "Part of Speech: noun.plant\n",
      "Definition: the ripened reproductive body of a seed plant\n",
      "Lemmas: ['fruit']\n",
      "Examples: []\n",
      "\n",
      "Synset: Synset('yield.n.03')\n",
      "Part of Speech: noun.artifact\n",
      "Definition: an amount of a product\n",
      "Lemmas: ['yield', 'fruit']\n",
      "Examples: []\n",
      "\n",
      "Synset: Synset('fruit.n.03')\n",
      "Part of Speech: noun.event\n",
      "Definition: the consequence of some effort or action\n",
      "Lemmas: ['fruit']\n",
      "Examples: ['he lived long enough to see the fruit of his policies']\n",
      "\n",
      "Synset: Synset('fruit.v.01')\n",
      "Part of Speech: verb.creation\n",
      "Definition: cause to bear fruit\n",
      "Lemmas: ['fruit']\n",
      "Examples: []\n",
      "\n",
      "Synset: Synset('fruit.v.02')\n",
      "Part of Speech: verb.creation\n",
      "Definition: bear fruit\n",
      "Lemmas: ['fruit']\n",
      "Examples: ['the trees fruited early this year']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for synset in synsets:\n",
    "    print('Synset:', synset)\n",
    "    print('Part of Speech:', synset.lexname())\n",
    "    print('Definition:', synset.definition())\n",
    "    print('Lemmas:', synset.lemma_names())\n",
    "    print('Examples:', synset.examples())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entailments\n",
    "\n",
    "The term entailments usually refers to some event or action that logically involves or is associated with some other action or event that has taken place or will take place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('walk.v.01') -- entails --> [Synset('step.v.01')]\n",
      "Synset('eat.v.01') -- entails --> [Synset('chew.v.01'), Synset('swallow.v.01')]\n",
      "Synset('digest.v.01') -- entails --> [Synset('consume.v.02')]\n"
     ]
    }
   ],
   "source": [
    "for action in ['walk', 'eat', 'digest']:\n",
    "    action_syn = wn.synsets(action, pos='v')[0]\n",
    "    print(action_syn, '-- entails -->', action_syn.entailments())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homonyms and Homographs\n",
    "\n",
    "Homonyms refer to words or terms having the same written form or pronunciation but different meanings. Homonyms are a superset of homographs, which are words with same spelling but may have different pronunciation and meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bank.n.01 - sloping land (especially the slope beside a body of water)\n",
      "depository_financial_institution.n.01 - a financial institution that accepts deposits and channels the money into lending activities\n",
      "bank.n.03 - a long ridge or pile\n",
      "bank.n.04 - an arrangement of similar objects in a row or in tiers\n",
      "bank.n.05 - a supply or stock held in reserve for future use (especially in emergencies)\n",
      "bank.n.06 - the funds held by a gambling house or the dealer in some gambling games\n",
      "bank.n.07 - a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force\n",
      "savings_bank.n.02 - a container (usually with a slot in the top) for keeping money at home\n",
      "bank.n.09 - a building in which the business of banking transacted\n",
      "bank.n.10 - a flight maneuver; aircraft tips laterally about its longitudinal axis (especially in turning)\n",
      "bank.v.01 - tip laterally\n",
      "bank.v.02 - enclose with a bank\n",
      "bank.v.03 - do business with a bank or keep an account at a bank\n",
      "bank.v.04 - act as the banker in a game or in gambling\n",
      "bank.v.05 - be in the banking business\n",
      "deposit.v.02 - put into a bank account\n",
      "bank.v.07 - cover with ashes so to control the rate of burning\n",
      "trust.v.01 - have confidence or faith in\n"
     ]
    }
   ],
   "source": [
    "for synset in wn.synsets('bank'):\n",
    "    print(synset.name(), '-', synset.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synonyms and antonyms\n",
    "\n",
    "Synonyms are words having similar meaning and context, and antonyms are words having opposite or contrasting meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonym: large.a.01\n",
      "Definition: above average in size or number or quantity or magnitude or extent\n",
      "Antonym: small.a.01\n",
      "Definition: limited or below average in number or quantity or magnitude or extent\n"
     ]
    }
   ],
   "source": [
    "term = 'large'\n",
    "synsets = wn.synsets(term)\n",
    "adj_large = synsets[1]\n",
    "adj_large = adj_large.lemmas()[0]\n",
    "adj_large_synonym = adj_large.synset()\n",
    "adj_large_antonym = adj_large.antonyms()[0].synset()\n",
    "\n",
    "# Print synonym and antonym.\n",
    "print('Synonym:', adj_large_synonym.name())\n",
    "print('Definition:', adj_large_synonym.definition())\n",
    "print('Antonym:', adj_large_antonym.name())\n",
    "print('Definition:', adj_large_antonym.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonym: rich_people.n.01\n",
      "Definition: people who have possessions and wealth (considered as a group)\n",
      "Antonym: poor_people.n.01\n",
      "Definition: people without possessions or wealth (considered as a group)\n",
      "Synonym: rich.a.01\n",
      "Definition: possessing material wealth\n",
      "Antonym: poor.a.02\n",
      "Definition: having little money or few possessions\n",
      "Synonym: rich.a.02\n",
      "Definition: having an abundant supply of desirable qualities or substances (especially natural resources)\n",
      "Antonym: poor.a.04\n",
      "Definition: lacking in specific resources, qualities or substances\n"
     ]
    }
   ],
   "source": [
    "term = 'rich'\n",
    "synsets = wn.synsets(term)[:3]\n",
    "\n",
    "# Print synonym and antonym for different synsets.\n",
    "for synset in synsets:\n",
    "    rich = synset.lemmas()[0]\n",
    "    rich_synonym = rich.synset()\n",
    "    rich_antonym = rich.antonyms()[0].synset()\n",
    "    \n",
    "    print('Synonym:', rich_synonym.name())\n",
    "    print('Definition:', rich_synonym.definition())\n",
    "\n",
    "\n",
    "    print('Antonym:', rich_antonym.name())\n",
    "    print('Definition:', rich_antonym.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyponyms and Hypernyms\n",
    "\n",
    "Hyponym refers to entities or concepts that are a subclass of a higher order concept or entity and have very specific sense or context compared to its superclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tree.n.01\n",
      "Definition: a tall perennial woody plant having a main trunk and branches forming a distinct elevated crown; includes both gymnosperms and angiosperms\n",
      "Total Hyponyms: 180\n",
      "Sample Hyponyms\n",
      "aalii.n.01 - a small Hawaiian tree with hard dark wood\n",
      "acacia.n.01 - any of various spiny trees or shrubs of the genus Acacia\n",
      "african_walnut.n.01 - tropical African timber tree with wood that resembles mahogany\n",
      "albizzia.n.01 - any of numerous trees of the genus Albizia\n",
      "alder.n.02 - north temperate shrubs or trees having toothed leaves and conelike fruit; bark is used in tanning and dyeing and the wood is rot-resistant\n",
      "angelim.n.01 - any of several tropical American trees of the genus Andira\n",
      "angiospermous_tree.n.01 - any tree having seeds and ovules contained in the ovary\n",
      "anise_tree.n.01 - any of several evergreen shrubs and small trees of the genus Illicium\n",
      "arbor.n.01 - tree (as opposed to shrub)\n",
      "aroeira_blanca.n.01 - small resinous tree or shrub of Brazil\n"
     ]
    }
   ],
   "source": [
    "term = 'tree'\n",
    "synsets = wn.synsets(term)\n",
    "tree = synsets[0]\n",
    "\n",
    "# Print the entity and its meaning.\n",
    "print('Name:', tree.name())\n",
    "print('Definition:', tree.definition())\n",
    "\n",
    "# Print total hyponyms and some sample hyponyms for 'tree'.\n",
    "hyponyms = tree.hyponyms()\n",
    "print('Total Hyponyms:', len(hyponyms))\n",
    "print('Sample Hyponyms')\n",
    "for hyponym in hyponyms[:10]:\n",
    "    print(hyponym.name(), '-', hyponym.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('woody_plant.n.01')]\n"
     ]
    }
   ],
   "source": [
    "hypernyms = tree.hypernyms()\n",
    "print(hypernyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Hypernym paths: 1\n"
     ]
    }
   ],
   "source": [
    "# Get total hierarchy pathways for tree.\n",
    "hypernym_paths = tree.hypernym_paths()\n",
    "print('Total Hypernym paths:', len(hypernym_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypernym Hierarchy\n",
      "entity.n.01 -> physical_entity.n.01 -> object.n.01 -> whole.n.02 -> living_thing.n.01 -> organism.n.01 -> plant.n.02 -> vascular_plant.n.01 -> woody_plant.n.01 -> tree.n.01\n"
     ]
    }
   ],
   "source": [
    "# Print the entire hypernym hierarchy.\n",
    "print('Hypernym Hierarchy')\n",
    "print(' -> '.join(synset.name() for synset in hypernym_paths[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holonyms and Meronyms\n",
    "\n",
    "\n",
    "Holonyms are entities that contains a specific entity of our interest. Basically holonyms refers to the relationship between a term or entity that denotes the whole and a term denoting a specific part of the whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total member holonyms: 1\n",
      "Member holonyms for [tree]:-\n",
      "forest.n.01 - the trees and other plants in a large densely wooded area\n"
     ]
    }
   ],
   "source": [
    "member_holonyms = tree.member_holonyms()\n",
    "print('Total member holonyms:', len(member_holonyms))\n",
    "print('Member holonyms for [tree]:-')\n",
    "for holonym in member_holonyms:\n",
    "    print(holonym.name(), '-', holonym.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Part Meronyms: 5\n",
      "Part Meronyms for [tree]:-\n",
      "burl.n.02 - a large rounded outgrowth on the trunk or branch of a tree\n",
      "crown.n.07 - the upper branches and leaves of a tree or other plant\n",
      "limb.n.02 - any of the main branches arising from the trunk or a bough of a tree\n",
      "stump.n.01 - the base part of a tree that remains standing after the tree has been felled\n",
      "trunk.n.01 - the main stem of a tree; usually covered with bark; the bole is usually the part that is commercially useful for lumber\n"
     ]
    }
   ],
   "source": [
    "# Part based meronyms for tree.\n",
    "part_meronyms = tree.part_meronyms()\n",
    "print('Total Part Meronyms:', len(part_meronyms))\n",
    "print('Part Meronyms for [tree]:-')\n",
    "for meronym in part_meronyms:\n",
    "    print(meronym.name(), '-', meronym.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total substance meronyms: 2\n",
      "heartwood.n.01 - the older inactive central wood of a tree or woody plant; usually darker and denser than the surrounding sapwood\n",
      "sapwood.n.01 - newly formed outer wood lying between the cambium and the heartwood of a tree or woody plant; usually light colored; active in water conduction\n"
     ]
    }
   ],
   "source": [
    "# Substance based meronyms for tree.\n",
    "substance_meronyms = tree.substance_meronyms()\n",
    "print('Total substance meronyms:', len(substance_meronyms))\n",
    "for meronym in substance_meronyms:\n",
    "    print(meronym.name(), '-', meronym.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic relationships and similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree - a tall perennial woody plant having a main trunk and branches forming a distinct elevated crown; includes both gymnosperms and angiosperms\n",
      "lion - large gregarious predatory feline of Africa and India having a tawny coat with a shaggy mane in the male\n",
      "tiger - large feline of forests in most of Asia having a tawny coat with black stripes; endangered\n",
      "cat - feline mammal usually having thick soft fur and no ability to roar: domestic cats; wildcats\n",
      "dog - a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n"
     ]
    }
   ],
   "source": [
    "tree = wn.synset('tree.n.01')\n",
    "lion = wn.synset('lion.n.01')\n",
    "tiger = wn.synset('tiger.n.02')\n",
    "cat = wn.synset('cat.n.01')\n",
    "dog = wn.synset('dog.n.01')\n",
    "\n",
    "# Create entities and extract names and definitions.\n",
    "entities = [tree, lion, tiger, cat, dog]\n",
    "entity_names = [entity.name().split('.')[0] for entity in entities]\n",
    "entity_definitions = [entity.definition() for entity in entities]\n",
    "\n",
    "# Print entities and their definitions.\n",
    "for entity, definition in zip(entity_names, entity_definitions):\n",
    "    print(entity, '-', definition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree</th>\n",
       "      <th>lion</th>\n",
       "      <th>tiger</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>tree</td>\n",
       "      <td>organism</td>\n",
       "      <td>organism</td>\n",
       "      <td>organism</td>\n",
       "      <td>organism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lion</th>\n",
       "      <td>organism</td>\n",
       "      <td>lion</td>\n",
       "      <td>big_cat</td>\n",
       "      <td>feline</td>\n",
       "      <td>carnivore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiger</th>\n",
       "      <td>organism</td>\n",
       "      <td>big_cat</td>\n",
       "      <td>tiger</td>\n",
       "      <td>feline</td>\n",
       "      <td>carnivore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>organism</td>\n",
       "      <td>feline</td>\n",
       "      <td>feline</td>\n",
       "      <td>cat</td>\n",
       "      <td>carnivore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>organism</td>\n",
       "      <td>carnivore</td>\n",
       "      <td>carnivore</td>\n",
       "      <td>carnivore</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tree       lion      tiger        cat        dog\n",
       "tree       tree   organism   organism   organism   organism\n",
       "lion   organism       lion    big_cat     feline  carnivore\n",
       "tiger  organism    big_cat      tiger     feline  carnivore\n",
       "cat    organism     feline     feline        cat  carnivore\n",
       "dog    organism  carnivore  carnivore  carnivore        dog"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_hypernyms = []\n",
    "for entity in entities:\n",
    "    # Get pairwise lowest common hypernyms.\n",
    "    common_hypernyms.append([entity.lowest_common_hypernyms(compared_entity)[0].name().split('.')[0]\n",
    "                             for compared_entity in entities])\n",
    "    \n",
    "# Build pairwise lower common hypernym matrix.\n",
    "common_hypernym_frame = pd.DataFrame(common_hypernyms,\n",
    "                                     index=entity_names,\n",
    "                                     columns=entity_names)\n",
    "\n",
    "# Print the matrix.\n",
    "common_hypernym_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree</th>\n",
       "      <th>lion</th>\n",
       "      <th>tiger</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lion</th>\n",
       "      <td>0.07</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiger</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tree  lion  tiger   cat   dog\n",
       "tree   1.00  0.07   0.07  0.08  0.12\n",
       "lion   0.07  1.00   0.33  0.25  0.17\n",
       "tiger  0.07  0.33   1.00  0.25  0.17\n",
       "cat    0.08  0.25   0.25  1.00  0.20\n",
       "dog    0.12  0.17   0.17  0.20  1.00"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities = []\n",
    "for entity in entities:\n",
    "    # Get pairwise similarities.\n",
    "    similarities.append([round(entity.path_similarity(compared_entity), 2)\n",
    "                         for compared_entity in entities])\n",
    "\n",
    "# Build pairwise similarity matrix.\n",
    "similarity_frame = pd.DataFrame(similarities,\n",
    "                                index=entity_names,\n",
    "                                columns=entity_names)\n",
    "\n",
    "similarity_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word sense disambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.wsd import lesk\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The fruits on that plant has ripened\n",
      "Word synset: Synset('fruit.n.01')\n",
      "Corresponding definition: the ripened reproductive body of a seed plant\n",
      "\n",
      "Sentence: He finally reaped the fruit of his hard work as he won the race\n",
      "Word synset: Synset('fruit.n.03')\n",
      "Corresponding definition: the consequence of some effort or action\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample text and word to disambiguate.\n",
    "samples = [('The fruits on that plant has ripened', 'n'),\n",
    "           ('He finally reaped the fruit of his hard work as he won the race', 'n')]\n",
    "word = 'fruit'\n",
    "\n",
    "# Perform word sense disambiguation.\n",
    "for sentence, pos_tag in samples:\n",
    "    word_syn = lesk(word_tokenize(sentence.lower()), word, pos_tag)\n",
    "    print('Sentence:', sentence)\n",
    "    print('Word synset:', word_syn)\n",
    "    print('Corresponding definition:', word_syn.definition())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Lead is a very soft, malleable metal\n",
      "Word synset: Synset('lead.n.02')\n",
      "Corresponding definition: a soft heavy toxic malleable metallic element; bluish white when freshly cut but tarnishes readily to dull grey\n",
      "\n",
      "Sentence: John is the actor who plays the lead in that movie\n",
      "Word synset: Synset('star.n.04')\n",
      "Corresponding definition: an actor who plays a principal role\n",
      "\n",
      "Sentence: This road leads to nowhere\n",
      "Word synset: Synset('run.v.23')\n",
      "Corresponding definition: cause something to pass or lead somewhere\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample text and word to disambiguate.\n",
    "samples = [('Lead is a very soft, malleable metal', 'n'),\n",
    "           ('John is the actor who plays the lead in that movie', 'n'),\n",
    "           ('This road leads to nowhere', 'v')]\n",
    "word = 'lead'\n",
    "\n",
    "# Perform word sense disambiguation.\n",
    "for sentence, pos_tag in samples:\n",
    "    word_syn = lesk(word_tokenize(sentence.lower()), word, pos_tag)\n",
    "    print('Sentence:', sentence)\n",
    "    print('Word synset:', word_syn)\n",
    "    print('Corresponding definition:', word_syn.definition())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named entity recognition\n",
    "NER, also known as entity chunking/extraction is a popular technique used in information extraction to identify and segment named entities and classify or categorize them under various predefined classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Bayern Munich, or FC Bayern, is a German sports club based in Munich, \n",
    "Bavaria, Germany. It is best known for its professional football team, \n",
    "which plays in the Bundesliga, the top tier of the German football \n",
    "league system, and is the most successful club in German football \n",
    "history, having won a record 26 national titles and 18 national cups. \n",
    "FC Bayern was founded in 1900 by eleven football players led by Franz John. \n",
    "Although Bayern won its first national championship in 1932, the club \n",
    "was not selected for the Bundesliga at its inception in 1963. The club \n",
    "had its period of greatest success in the middle of the 1970s when, \n",
    "under the captaincy of Franz Beckenbauer, it won the European Cup three \n",
    "times in a row (1974-76). Overall, Bayern has reached ten UEFA Champions \n",
    "League finals, most recently winning their fifth title in 2013 as part \n",
    "of a continental treble. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity Name</th>\n",
       "      <th>Entity Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FC Bayern</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>German</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Munich</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Munich</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bayern</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bavaria</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Franz John</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UEFA</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Overall</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Franz Beckenbauer</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bundesliga</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>European</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bayern</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Entity Name   Entity Type\n",
       "0           FC Bayern  ORGANIZATION\n",
       "1              German           GPE\n",
       "2             Germany           GPE\n",
       "3              Munich           GPE\n",
       "4              Munich  ORGANIZATION\n",
       "5              Bayern           GPE\n",
       "6             Bavaria           GPE\n",
       "7          Franz John        PERSON\n",
       "8                UEFA  ORGANIZATION\n",
       "9             Overall           GPE\n",
       "10  Franz Beckenbauer        PERSON\n",
       "11         Bundesliga  ORGANIZATION\n",
       "12           European  ORGANIZATION\n",
       "13             Bayern        PERSON"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from module.normalization import parse_document\n",
    "import pandas as pd\n",
    "\n",
    "# Tokenize sentences.\n",
    "sentences = parse_document(text)\n",
    "tokenized_sentences = [nltk.word_tokenize(sentence) \n",
    "                       for sentence in sentences]\n",
    "\n",
    "# Tag sentences and use nltk's Named Entity Chunker.\n",
    "tagged_sentences = [nltk.pos_tag(sentence) for sentence in tokenized_sentences]\n",
    "ne_chunked_sents = [nltk.ne_chunk(tagged) for tagged in tagged_sentences]\n",
    "\n",
    "\n",
    "# Extract all named entities.\n",
    "named_entities = []\n",
    "for ne_tagged_sentence in ne_chunked_sents:\n",
    "    for tagged_tree in ne_tagged_sentence:\n",
    "        # Extract only chunks having NE labels.\n",
    "        if hasattr(tagged_tree, 'label'):\n",
    "            entity_name = ' '.join(c[0] for c in tagged_tree.leaves()) # Get NE name.\n",
    "            entity_type = tagged_tree.label() # Get NE category.\n",
    "            named_entities.append((entity_name, entity_type))\n",
    "# Get unique named entities.\n",
    "named_entities = list(set(named_entities))\n",
    "\n",
    "# Store named entities in a data frame.\n",
    "entity_frame = pd.DataFrame(named_entities, \n",
    "                            columns=['Entity Name', 'Entity Type'])\n",
    "entity_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE: SKIP Standford NER Tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propositional Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: He is hungry\n",
      "Q: He will eat a sandwich\n",
      "\n",
      "Expression Outcomes:-\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>Q</th>\n",
       "      <th>(P &amp; Q)</th>\n",
       "      <th>(P | Q)</th>\n",
       "      <th>(P -&gt; Q)</th>\n",
       "      <th>(P &lt;-&gt; Q)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       P      Q  (P & Q)  (P | Q)  (P -> Q)  (P <-> Q)\n",
       "0  False  False    False    False      True       True\n",
       "1  False   True    False     True      True      False\n",
       "2   True  False    False     True     False      False\n",
       "3   True   True     True     True      True       True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign symbols and propositions.\n",
    "symbol_P = 'P'\n",
    "symbol_Q = 'Q'\n",
    "proposition_P = 'He is hungry'\n",
    "proposition_Q = 'He will eat a sandwich'\n",
    "\n",
    "# Assign various truth values to the proposition.\n",
    "p_statuses = [False, False, True, True]\n",
    "q_statuses = [False, True, False, True]\n",
    "\n",
    "# Assign the various expressions combining the logical operators.\n",
    "conjunction = '(P & Q)'\n",
    "disjunction = '(P | Q)'\n",
    "implication = '(P -> Q)'\n",
    "equivalence = '(P <-> Q)'\n",
    "expressions = [conjunction, disjunction, implication, equivalence]\n",
    "\n",
    "# Evaluate each expression using propositional logic.\n",
    "results = []\n",
    "\n",
    "for status_p, status_q in zip(p_statuses, q_statuses):\n",
    "    dom = set([])\n",
    "    val = nltk.Valuation([(symbol_P, status_p), \n",
    "                          (symbol_Q, status_q)])\n",
    "    assignments = nltk.Assignment(dom)\n",
    "    model = nltk.Model(dom, val)\n",
    "    row = [status_p, status_q]\n",
    "    for expression in expressions:\n",
    "        # Evaluate each expression based on proposition truth values.\n",
    "        result = model.evaluate(expression, assignments)\n",
    "        row.append(result)\n",
    "    results.append(row)\n",
    "\n",
    "# Build the result table.\n",
    "columns = [symbol_P, symbol_Q, conjunction, \n",
    "           disjunction, \n",
    "           implication,\n",
    "           equivalence]\n",
    "\n",
    "result_frame = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "# Display results.\n",
    "\n",
    "print('P:', proposition_P)\n",
    "print('Q:', proposition_Q)\n",
    "print()\n",
    "print('Expression Outcomes:-')\n",
    "result_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from module.normalization import normalize_corpus\n",
    "from module.utils import build_feature_matrix, display_evaluation_metrics, display_confusion_matrix, display_classification_report\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('movie_reviews.csv')\n",
    "dataset = dataset.head(10_000)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1_000 # 35_000\n",
    "train_data = dataset[:n]\n",
    "test_data = dataset[n:n+n]\n",
    "\n",
    "train_reviews = np.array(train_data['review'])\n",
    "train_sentiments = np.array(train_data['sentiment'])\n",
    "test_reviews = np.array(test_data['review'])\n",
    "test_sentiments = np.array(test_data['sentiment'])\n",
    "\n",
    "# Prepare sample dataset for experiments.\n",
    "# sample_docs = [100, 5817, 7626, 7356, 1008, 7155, 3533, 13010]\n",
    "sample_docs = [100, 581, 762, 735, 100, 715, 353, 130]\n",
    "sample_data = [(test_reviews[index], test_sentiments[index])\n",
    "               for index in sample_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization.\n",
    "norm_train_reviews = normalize_corpus(train_reviews, lemmatize=True, only_text_chars=True)\n",
    "\n",
    "# Feature extraction.\n",
    "vectorizer, train_features = build_feature_matrix(documents=norm_train_reviews,\n",
    "                                                  feature_type='tfidf',\n",
    "                                                  ngram_range=(1, 1),\n",
    "                                                  min_df=0.0,\n",
    "                                                  max_df=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=200, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Build the model.\n",
    "svm = SGDClassifier(loss='hinge', max_iter=200)\n",
    "svm.fit(train_features, train_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize reviews.\n",
    "norm_test_reviews = normalize_corpus(test_reviews, lemmatize=True, only_text_chars=True)\n",
    "\n",
    "# Extract features.\n",
    "test_features = vectorizer.transform(norm_test_reviews)\n",
    "\n",
    "# Predict sentiment for sample docs from test data.\n",
    "for doc_index in sample_docs:\n",
    "    print('Review:-')\n",
    "    print(test_reviews[doc_index])\n",
    "    print('Actual labeled sentiment:', test_sentiments[doc_index])\n",
    "    doc_features = test_features[doc_index]\n",
    "    predicted_sentiment = svm.predict(doc_features)[0]\n",
    "    print('Predicted sentiment:', predicted_sentiment)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the sentiment for test dataset movie reviews.\n",
    "predicted_sentiments = svm.predict(test_features)\n",
    "\n",
    "# Evaluate model prediction performance.\n",
    "# Show performance metrics.\n",
    "display_evaluation_metrics(true_labels=test_sentiments,\n",
    "                           predicted_labels=predicted_sentiments,\n",
    "                           positive_class='positive')\n",
    "\n",
    "# Show confusion matrix.\n",
    "display_confusion_matrix(true_labels=test_sentiments,\n",
    "                         predicted_labels=predicted_sentiments,\n",
    "                         classes=['positive', 'negative'])\n",
    "\n",
    "# Show detailed per-class classification report.\n",
    "display_classification_report(true_labels=test_sentiments,\n",
    "                              predicted_labels=predicted_sentiments,\n",
    "                              classes=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised lexicon-based techniques\n",
    "\n",
    "- AFINN lexicon\n",
    "- Bing Liu's lexicon\n",
    "- MPQA subjectivity lexicon\n",
    "- SentiWordNet\n",
    "- VADER lexicon\n",
    "- Pattern lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AFINN Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from afinn import Afinn\n",
    "\n",
    "afn = Afinn(emoticons=True)\n",
    "afn.score('I really hated the plot of this movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afn.score('I really hated the plot of this movie :(')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SentiWordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "# Get synset for 'good'.\n",
    "good = list(swn.senti_synsets('good', 'n'))[0]\n",
    "\n",
    "# Print synset sentiment scores.\n",
    "print('Positive polarity score:', good.pos_score())\n",
    "print('Negative polarity score:', good.neg_score())\n",
    "print('Objective score:', good.obj_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.normalization import normalize_accented_characters, strip_html\n",
    "import html\n",
    "\n",
    "def safe_list(l, i=0):\n",
    "    return l[i] if len(l) > i else None\n",
    "\n",
    "def analyze_sentiment_sentiwordnet_lexicon(review, verbose=False):\n",
    "    # Pre-process text.\n",
    "    review = normalize_accented_characters(review)\n",
    "    review = html.unescape(review.decode('utf-8'))\n",
    "    review = strip_html(review)\n",
    "    \n",
    "    # Tokenize and POS tag text tokens.\n",
    "    text_tokens = nltk.word_tokenize(review)\n",
    "    tagged_text = nltk.pos_tag(text_tokens)\n",
    "    pos_score = neg_score = token_count = obj_score = 0\n",
    "    \n",
    "    # Get word synsets based on POS tags.\n",
    "    # Get sentiment scores if synsets are found.\n",
    "    for word, tag in tagged_text:\n",
    "        ss_set = None\n",
    "        if 'NN' in tag and swn.senti_synsets(word, 'n'):\n",
    "            ss_set = safe_list(list(swn.senti_synsets(word, 'n')))\n",
    "        elif 'VB' in tag and swn.senti_synsets(word, 'v'):\n",
    "            ss_set = safe_list(list(swn.senti_synsets(word, 'v')))\n",
    "        elif 'JJ' in tag and swn.senti_synsets(word, 'a'):\n",
    "            ss_set = safe_list(list(swn.senti_synsets(word, 'a')))\n",
    "        elif 'RB' in tag and swn.senti_synsets(word, 'r'):\n",
    "            ss_set = safe_list(list(swn.senti_synsets(word, 'r')))\n",
    "        \n",
    "        if ss_set:\n",
    "            # If senti-synset is found.\n",
    "            # Add scores for all found synsets.\n",
    "            pos_score += ss_set.pos_score()\n",
    "            neg_score += ss_set.neg_score()\n",
    "            obj_score += ss_set.obj_score()\n",
    "            token_count += 1\n",
    "    \n",
    "    # Aggregate final scores.\n",
    "    final_score = pos_score - neg_score\n",
    "    norm_final_score = round(float(final_score)/token_count, 2)\n",
    "    final_sentiment = 'positive' if norm_final_score > 0 else 'negative'\n",
    "    if verbose:\n",
    "        norm_obj_score = round(float(obj_score) / token_count, 2)\n",
    "        norm_pos_score = round(float(pos_score) / token_count, 2)\n",
    "        norm_neg_score = round(float(neg_score) / token_count, 2)\n",
    "        \n",
    "        # To display results in a nice table.\n",
    "        sentiment_frame = pd.DataFrame([[final_sentiment, norm_obj_score, \n",
    "                                         norm_pos_score,\n",
    "                                         norm_neg_score,\n",
    "                                         norm_final_score]],\n",
    "                                       columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'],\n",
    "                                                                     ['Predicted Sentiment',\n",
    "                                                                      'Objectivity',\n",
    "                                                                      'Positive',\n",
    "                                                                      'Negative',\n",
    "                                                                      'Overall']],\n",
    "                                                            codes=[[0,0,0,0,0], [0,1,2,3,4]]))\n",
    "        print(sentiment_frame)\n",
    "    return final_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for review, review_sentiment in sample_data:\n",
    "    print('Review:')\n",
    "    print(review)\n",
    "    print()\n",
    "    print('Labeled sentiment:', review_sentiment)\n",
    "    print()\n",
    "    final_sentiment = analyze_sentiment_sentiwordnet_lexicon(review, verbose=True)\n",
    "    print('-' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict sentiment for test movie reviews dataset.\n",
    "sentiwordnet_predictions = [analyze_sentiment_sentiwordnet_lexicon(review)\n",
    "                            for review in test_reviews]\n",
    "\n",
    "# Get model performance statistics.\n",
    "print('Performance metrics:')\n",
    "display_evaluation_metrics(true_labels=test_sentiments,\n",
    "                           predicted_labels=sentiwordnet_predictions,\n",
    "                           positive_class='positive')\n",
    "print()\n",
    "print('Confusion Matrix:')\n",
    "display_confusion_matrix(true_labels=test_sentiments,\n",
    "                         predicted_labels=sentiwordnet_predictions,\n",
    "                         classes=['positive', 'negative'])\n",
    "\n",
    "print()\n",
    "print('Classification Report:')\n",
    "display_classification_report(true_labels=test_sentiments,\n",
    "                              predicted_labels=sentiwordnet_predictions,\n",
    "                              classes=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VADER Lexicon\n",
    "\n",
    "VADER stands for Valence Aware Dictionary and sEntiment Reasoner. It is a lexicon with a rule-based sentiment analysis framework that was specially built for analyzing sentiment from social media resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "def analyze_sentiment_vader_lexicon(review,\n",
    "                                    threhold=0.1,\n",
    "                                    verbose=False):\n",
    "    # Pre-process text.\n",
    "    review = normalize_accented_characters(review)\n",
    "    review = html.unescape(review.decode('utf-8'))\n",
    "    review = strip_html(review)\n",
    "    \n",
    "    # Analyze the sentiment for review.\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(review)\n",
    "    \n",
    "    # Get aggregate scores and final sentiment.\n",
    "    agg_score = scores['compound']\n",
    "    \n",
    "    final_sentiment = 'positive' if agg_score >= threshold else 'negative'\n",
    "    \n",
    "    if verbose:\n",
    "        # Display detailed sentiment statistics.\n",
    "        positive = str(round(scores['pos'], 2) * 100) + '%'\n",
    "        final = round(agg_score, 2)\n",
    "        negative = str(round(scores['neg'], 2) * 100) + '%'\n",
    "        neutral = str(round(scores['neu'], 2) * 100) + '%'\n",
    "        sentiment_frame = pd.DataFrame([[final_sentiment, final, positive, negative, neutral]],\n",
    "                                       columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'],\n",
    "                                                                     ['Predicted Sentiment',\n",
    "                                                                      'Polarity Score',\n",
    "                                                                      'Positive',\n",
    "                                                                      'Negative',\n",
    "                                                                      'Neutral']],\n",
    "                                                            labels=[[0, 0, 0, 0, 0], [0, 1, 2, 3, 4]]))\n",
    "        print(sentiment_frame)\n",
    "    return final_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get detailed sentiment statistics.\n",
    "for review, review_sentiment in sample_data:\n",
    "    print('Review:')\n",
    "    print(review)\n",
    "    print()\n",
    "    print('Labeled Sentiment:', review_sentiment)\n",
    "    print()\n",
    "    final_sentiment = analyze_sentiment_vader_lexicon(review,\n",
    "                                                      threshold=0.1,\n",
    "                                                      verbose=True)\n",
    "    print('-' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_predictions = [analyze_sentiment_vader_lexicon(review, threshold=0.1)\n",
    "                     for review in test_reviews]\n",
    "\n",
    "# Get model performance statistics.\n",
    "print('Performance metrics:')\n",
    "display_evaluation_metrics(true_labels=test_sentiments,\n",
    "                           predicted_labels=vader_predictions,\n",
    "                           positive_class='positive')\n",
    "\n",
    "print('\\nConfusion matrix:')\n",
    "display_confusion_matrix(true_labels=test_sentiments,\n",
    "                         predicted_labels=vader_predictions,\n",
    "                         classes=['positive', 'negative'])\n",
    "\n",
    "print('\\Classification report:')\n",
    "display_classfication_report(true_labels=test_sentiments,\n",
    "                             predicted_labels=vader_predictions,\n",
    "                             classes=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pattern.en import sentiment, mood, modality\n",
    "\n",
    "def analyze_sentiment_pattern_lexicon(review, threshold=0.1, verbose=False):\n",
    "    # Pre-process text.\n",
    "    review = normalize_accented_characters(review)\n",
    "    review = html.unescape(review.decode('utf-8'))\n",
    "    review = strip_html(review)\n",
    "    \n",
    "    # Analyze sentiment for the text document.\n",
    "    analysis = sentiment(review)\n",
    "    sentiment_score = round(analysis[0], 2)\n",
    "    sentiment_subjectivity = round(analysis[1], 2)\n",
    "    \n",
    "    # Get final sentiment.\n",
    "    final_sentiment = 'positive' if sentiment_score >= threshold else 'negative'\n",
    "    if verbose:\n",
    "        # Display detailed sentiment statistics.\n",
    "        sentiment_frame = pd.DataFrame([[final_sentiment, sentiment_score, sentiment_subjectivity]],\n",
    "                                       columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'],\n",
    "                                                                     ['Predicted Sentiment',\n",
    "                                                                      'Polarity Score',\n",
    "                                                                      'Subjectivity Score']],\n",
    "                                                             labels=[[0, 0, 0], [0, 1, 2]]))\n",
    "        print(sentiment_frame)\n",
    "        assessment = analysis.assessments\n",
    "        assessment_frame = pd.DataFrame(assessment,\n",
    "                                        columns=pd.MultiIndex(levels=[['DETAILED ASSESSMENT STATS:'],\n",
    "                                                                      ['Key Terms', 'Polarity Score',\n",
    "                                                                       'Subjectivity Score', 'Type']],\n",
    "                                                              labels=[[0, 0, 0, 0], [0,1,2,3]]))\n",
    "        print(assessment_frame)\n",
    "    return final_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get detailed sentiment statistics.\n",
    "for review, review_sentiment in sample_data:\n",
    "    print('Review:')\n",
    "    print(review)\n",
    "    print()\n",
    "    print('Labeled sentiment:', review_sentiment)\n",
    "    print()\n",
    "    final_sentiment = analyze_sentiment_pattern_lexicon(review, threshold=0.1, verbose=True)\n",
    "    print('-' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for review, review_sentiment in sample_data:\n",
    "    print('Review:')\n",
    "    print(review)\n",
    "    print('Labeled sentiment:', review_sentiment)\n",
    "    print('Mood:', mood(review))\n",
    "    mod_score = modality(review)\n",
    "    print('Modality score:', round(mod_score, 2))\n",
    "    print('Certainty: ', 'Strong' if mod_score > 0.5 else 'Medium' if mod_score > 0.35 else 'Low')\n",
    "    print('-' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict sentiment for test movie reviews dataset.\n",
    "pattern_predictions = [analyze_sentiment_pattern_lexicon(review, threshold=0.1) for review in test_reviews]\n",
    "\n",
    "# Get model performance statistics.\n",
    "print('Performance statistics:')\n",
    "display_evaluation_metrics(true_labels=test_sentiments,\n",
    "                           predicted_labels=pattern_predictions,\n",
    "                           positive_class='positive')\n",
    "\n",
    "print('\\nConfusion matrix:')\n",
    "display_confusion_matrix(true_labels=test_sentiments,\n",
    "                         predicted_labels=pattern_predictions,\n",
    "                         classes=['positive', 'negative'])\n",
    "\n",
    "print('\\nClassification report:')\n",
    "display_classification_report(true_labels=test_sentiments,\n",
    "                              predicted_labels=pattern_predictions,\n",
    "                              classes=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
