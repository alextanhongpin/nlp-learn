{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list = stopword_list + ['mr', 'ms', 'come', 'go', 'get', 'tell', 'listen', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'zero', 'join', 'find', 'make', 'say', 'ask', 'tell', 'see', 'try', 'back', 'also']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def keep_text_characters(text):\n",
    "    filtered_tokens = []\n",
    "    tokens = tokenize_text(text)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.contractions import expand_contractions\n",
    "from module.lemmatize import lemmatize_text\n",
    "\n",
    "def normalize_corpus(corpus, lemmatize=True,\n",
    "                     only_text_chars=False,\n",
    "                     tokenize=False):\n",
    "    normalized_corpus = []\n",
    "    for text in corpus:\n",
    "        text = html.unescape(text)\n",
    "        text = expand_contractions(text)\n",
    "    if lemmatize:\n",
    "        text = lemmatize_text(text)\n",
    "    else:\n",
    "        text = text.lower()\n",
    "    text = remove_special_characters(text)\n",
    "    text = remove_stopwords(text)\n",
    "    if only_text_chars:\n",
    "        text = keep_text_characters(text)\n",
    "    if tokenize:\n",
    "        text = tokenize_text(text)\n",
    "        normalized_corpus.append(text)\n",
    "    else:\n",
    "        normalized_corpus.append(text)\n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "def build_feature_matrix(documents, feature_type='frequency', ngram_range=(1,1), min_df=0.0, max_df=1.0):\n",
    "    feature_type = feature_type.lower().strip()\n",
    "    \n",
    "    if feature_type == 'binary':\n",
    "        vectorizer = CountVectorizer(binary=True, min_df=min_df,\n",
    "                                     max_df=max_df, \n",
    "                                     ngram_range=ngram_range)\n",
    "    elif feature_type == 'frequency':\n",
    "        vectorizer = CountVectorizer(binary=False, min_df=min_df,\n",
    "                                     max_df=max_df, ngram_range=ngram_range)\n",
    "    elif feature_type == 'tfidf':\n",
    "        vectorizer = TfidfVectorizer(min_df=min_df, max_df=max_df,\n",
    "                                     ngram_range=ngram_range)\n",
    "    else:\n",
    "        raise Exception('Wrong feature type entered. Possible values: \"binary\", \"frequency\", \"tfidf\".')\n",
    "        \n",
    "    feature_matrix = vectorizer.fit_transform(documents).astype(float)\n",
    "    \n",
    "    return vectorizer, feature_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text similarity\n",
    "\n",
    "Analyzing text similarity:\n",
    "\n",
    "- lexical similarity: observing the contents of the text documents with regard to syntax, structure and content and measuring their similarity based on these parameters\n",
    "- semantic similarity: trying to find out the semantics, meaning and context of the documents and then trying to see how close they are to each other. Dependency grammars and entity recognition are handy tools that can help in this.\n",
    "\n",
    "Lexical similarity is more straightforward to implement.\n",
    "\n",
    "Two broad areas of text similarity:\n",
    "- term similarity: measure similarity between individual tokens or words\n",
    "- document similarity: measure similarity between entire text documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing term similarity\n",
    "\n",
    "Word representations\n",
    "- character vectorization\n",
    "- bag of characters vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_terms(terms):\n",
    "    terms = [term.lower() for term in terms]\n",
    "    terms = [np.array(list(term)) for term in terms]\n",
    "    terms = [np.array([ord(char) for char in term])\n",
    "             for term in terms]\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of character vectorization is similar to the bag of words model except here we compute the frequency of each character in the word.\n",
    "\n",
    "def boc_term_vectors(word_list):\n",
    "    word_list = [word.lower() for word in word_list]\n",
    "    unique_chars = np.unique(\n",
    "     np.hstack([list(word)\n",
    "                for word in word_list]))\n",
    "    word_list_term_counts = [{char: count for char, count in zip(*np.unique(list(word), return_counts=True))} for word in word_list]\n",
    "    boc_vectors = [np.array([int(word_term_counts.get(char, 0))\n",
    "                             for char in unique_chars])\n",
    "                   for word_term_counts in word_list_term_counts]\n",
    "\n",
    "    return list(unique_chars), boc_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'Believe'\n",
    "term1 = 'beleive'\n",
    "term2 = 'bargain'\n",
    "term3 = 'Elephant'\n",
    "\n",
    "terms = [root, term1, term2, term3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 98, 101, 108, 105, 101, 118, 101]),\n",
       " array([ 98, 101, 108, 101, 105, 118, 101]),\n",
       " array([ 98,  97, 114, 103,  97, 105, 110]),\n",
       " array([101, 108, 101, 112, 104,  97, 110, 116]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Character vectorization.\n",
    "vec_root, vec_term1, vec_term2, vec_term3 = vectorize_terms(terms)\n",
    "vec_root, vec_term1, vec_term2, vec_term3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['a', 'b', 'e', 'g', 'h', 'i', 'l', 'n', 'p', 'r', 't', 'v'],\n",
       " (array([0, 1, 3, 0, 0, 1, 1, 0, 0, 0, 0, 1]),\n",
       "  array([0, 1, 3, 0, 0, 1, 1, 0, 0, 0, 0, 1]),\n",
       "  array([2, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0]),\n",
       "  array([1, 0, 2, 0, 1, 0, 1, 1, 1, 0, 1, 0])))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bag of characters vectorization.\n",
    "features, (boc_root, boc_term1, boc_term2, boc_term3) = boc_term_vectors(terms)\n",
    "print('Features')\n",
    "features, (boc_root, boc_term1, boc_term2, boc_term3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring similarity distance\n",
    "\n",
    "- hamming distance\n",
    "- manhattan distance\n",
    "- euclidean distance\n",
    "- levenshtein edit distance\n",
    "- cosine distance and similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_term = root\n",
    "root_vector = vec_root\n",
    "root_boc_vector = boc_root\n",
    "\n",
    "terms = [term1, term2, term3]\n",
    "vector_terms = [vec_term1, vec_term2, vec_term3]\n",
    "boc_vector_terms = [boc_term1, boc_term2, boc_term3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hamming distance\n",
    "\n",
    "Distance measured between two strings under the assumptions that they are of equal length. Hamming distance is defined as the number of positions that have different characters or symbols between two strings of equal length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_distance(u, v, norm=False):\n",
    "    if u.shape != v.shape:\n",
    "        raise ValueError('The vectors must have equal length')\n",
    "    return (u != v).sum() if not norm else (u != v).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming distance between root: Believe and term beleive is: 2\n",
      "Hamming distance between root: Believe and term bargain is: 6\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The vectors must have equal length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-67f4952a8c08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compute hamming distance.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_term\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_terms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Hamming distance between root: {root_term} and term {term} is: {hamming_distance(root_vector, vector_term, norm=False)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-3a96688e0091>\u001b[0m in \u001b[0;36mhamming_distance\u001b[0;34m(u, v, norm)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhamming_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The vectors must have equal length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The vectors must have equal length"
     ]
    }
   ],
   "source": [
    "# Compute hamming distance.\n",
    "for term, vector_term in zip(terms, vector_terms):\n",
    "    print(f'Hamming distance between root: {root_term} and term {term} is: {hamming_distance(root_vector, vector_term, norm=False)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming distance between root: Believe and term beleive is: 0.29\n",
      "Hamming distance between root: Believe and term bargain is: 0.86\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The vectors must have equal length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-822bb5e53daf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compute normalized Hamming distance.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_term\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_terms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Hamming distance between root: {root_term} and term {term} is: {round(hamming_distance(root_vector, vector_term, norm=True), 2)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-3a96688e0091>\u001b[0m in \u001b[0;36mhamming_distance\u001b[0;34m(u, v, norm)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhamming_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The vectors must have equal length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The vectors must have equal length"
     ]
    }
   ],
   "source": [
    "# Compute normalized Hamming distance.\n",
    "for term, vector_term in zip(terms, vector_terms):\n",
    "    print(f'Hamming distance between root: {root_term} and term {term} is: {round(hamming_distance(root_vector, vector_term, norm=True), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manhattan distance\n",
    "\n",
    "Also known as _city block distance_, _L1 norm_, _taxicab metric_ and is defined as the distance between two points in a grid based on strictly horizontal or vertical paths instead of the diagonal distance conventionally calculated by the Euclidean distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(u, v, norm=False):\n",
    "    if u.shape != v.shape:\n",
    "        raise ValueError('The vectors must have equal lengths.')\n",
    "    return abs(u - v).sum() if not norm else abs(u - v).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan distance between root: Believe and term beleive is: 8\n",
      "Manhattan distance between root: Believe and term bargain is: 38\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The vectors must have equal lengths.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-5ddc0a45be6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compute Manhattan distance.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_term\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_terms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Manhattan distance between root: {root_term} and term {term} is: {manhattan_distance(root_vector, vector_term, norm=False)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-f76af5f725e0>\u001b[0m in \u001b[0;36mmanhattan_distance\u001b[0;34m(u, v, norm)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmanhattan_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The vectors must have equal lengths.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The vectors must have equal lengths."
     ]
    }
   ],
   "source": [
    "# Compute Manhattan distance.\n",
    "for term, vector_term in zip(terms, vector_terms):\n",
    "    print(f'Manhattan distance between root: {root_term} and term {term} is: {manhattan_distance(root_vector, vector_term, norm=False)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan distance between root: Believe and term beleive is: 1.14\n",
      "Manhattan distance between root: Believe and term bargain is: 5.43\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The vectors must have equal lengths.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-a544477077da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compute normalized Manhattan distance.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_term\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_terms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Manhattan distance between root: {root_term} and term {term} is: {round(manhattan_distance(root_vector, vector_term, norm=True), 2)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-f76af5f725e0>\u001b[0m in \u001b[0;36mmanhattan_distance\u001b[0;34m(u, v, norm)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmanhattan_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The vectors must have equal lengths.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The vectors must have equal lengths."
     ]
    }
   ],
   "source": [
    "# Compute normalized Manhattan distance.\n",
    "for term, vector_term in zip(terms, vector_terms):\n",
    "    print(f'Manhattan distance between root: {root_term} and term {term} is: {round(manhattan_distance(root_vector, vector_term, norm=True), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Euclidean distance\n",
    "\n",
    "Euclidean distance is also known as the _euclidean norm_, _l2 norm_, or _l2 distance_ and is defined as the shortest straight line distance between two points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(u, v):\n",
    "    if u.shape != v.shape:\n",
    "        raise ValueError('The vectors must have equal lengths.')\n",
    "    distance = np.sqrt(np.sum(np.square(u - v)))\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance between root Believe and term beleive is 5.66\n",
      "Euclidean distance between root Believe and term bargain is 17.94\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The vectors must have equal lengths.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-558c73802740>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     print('Euclidean distance between root {} and term {} is {}'.format(root_term,\n\u001b[1;32m      4\u001b[0m                                                                         \u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                                                                         round(euclidean_distance(root_vector, vector_term), 2)))\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-c10226900814>\u001b[0m in \u001b[0;36meuclidean_distance\u001b[0;34m(u, v)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0meuclidean_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The vectors must have equal lengths.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The vectors must have equal lengths."
     ]
    }
   ],
   "source": [
    "# Compute euclidean distance.\n",
    "for term, vector_term in zip(terms, vector_terms):\n",
    "    print('Euclidean distance between root {} and term {} is {}'.format(root_term,\n",
    "                                                                        term,\n",
    "                                                                        round(euclidean_distance(root_vector, vector_term), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Levenshtein edit distance\n",
    "\n",
    "Defined as the minimum number of edits needed in the form of additions, deletions or substitutions to change or convert one term to the other. The length of two terms need not be equal here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "def levenshtein_edit_distance(u, v):\n",
    "    # Convert to lower case.\n",
    "    u = u.lower()\n",
    "    v = v.lower()\n",
    "    \n",
    "    # Base cases.\n",
    "    if u == v: return 0\n",
    "    elif len(u) == 0: return len(v)\n",
    "    elif len(v) == 0: return len(u)\n",
    "    \n",
    "    # Initialize edit distance matrix.\n",
    "    edit_matrix = []\n",
    "    \n",
    "    # Initialize two distance matrices.\n",
    "    du = [0] * (len(v) + 1)\n",
    "    dv = [0] * (len(v) + 1)\n",
    "    \n",
    "    # du: the previous row of edit distances.\n",
    "    for i in range(len(du)):\n",
    "        du[i] = i\n",
    "        \n",
    "    # dv: the current row of edit distances.\n",
    "    for i in range(len(u)):\n",
    "        dv[0] = i + 1\n",
    "        \n",
    "        # Compute cost as per algorithm.\n",
    "        for j in range(len(v)):\n",
    "            cost = 0 if u[i] == v[j] else 1\n",
    "            dv[j + 1] = min(dv[j] + 1, du[j + 1] + 1, du[j] + cost)\n",
    "        \n",
    "        # Assign dv to du for next iteration.\n",
    "        for j in range(len(du)):\n",
    "            du[j] = dv[j]\n",
    "        \n",
    "        # Copy dv to the edit matrix.\n",
    "        edit_matrix.append(copy.copy(dv))\n",
    "        \n",
    "    # Compute the final edit distance and edit matrix.\n",
    "    distance = dv[len(v)]\n",
    "    edit_matrix = np.array(edit_matrix)\n",
    "    edit_matrix = edit_matrix.T\n",
    "    edit_matrix = edit_matrix[1:,]\n",
    "    edit_matrix = pd.DataFrame(data=edit_matrix,\n",
    "                               index=list(v),\n",
    "                               columns=list(u))\n",
    "    return distance, edit_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing distance between root: Believe and term: beleive\n",
      "Levenshtein edit distance is 2\n",
      "The complete edit distance matrix is depicted below\n",
      "   b  e  l  i  e  v  e\n",
      "b  0  1  2  3  4  5  6\n",
      "e  1  0  1  2  3  4  5\n",
      "l  2  1  0  1  2  3  4\n",
      "e  3  2  1  1  1  2  3\n",
      "i  4  3  2  1  2  2  3\n",
      "v  5  4  3  2  2  2  3\n",
      "e  6  5  4  3  2  3  2\n",
      "------------------------------\n",
      "Computing distance between root: Believe and term: bargain\n",
      "Levenshtein edit distance is 6\n",
      "The complete edit distance matrix is depicted below\n",
      "   b  e  l  i  e  v  e\n",
      "b  0  1  2  3  4  5  6\n",
      "a  1  1  2  3  4  5  6\n",
      "r  2  2  2  3  4  5  6\n",
      "g  3  3  3  3  4  5  6\n",
      "a  4  4  4  4  4  5  6\n",
      "i  5  5  5  4  5  5  6\n",
      "n  6  6  6  5  5  6  6\n",
      "------------------------------\n",
      "Computing distance between root: Believe and term: Elephant\n",
      "Levenshtein edit distance is 7\n",
      "The complete edit distance matrix is depicted below\n",
      "   b  e  l  i  e  v  e\n",
      "e  1  1  2  3  4  5  6\n",
      "l  2  2  1  2  3  4  5\n",
      "e  3  2  2  2  2  3  4\n",
      "p  4  3  3  3  3  3  4\n",
      "h  5  4  4  4  4  4  4\n",
      "a  6  5  5  5  5  5  5\n",
      "n  7  6  6  6  6  6  6\n",
      "t  8  7  7  7  7  7  7\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for term in terms:\n",
    "    edit_d, edit_m = levenshtein_edit_distance(root_term, term)\n",
    "    print(f'Computing distance between root: {root_term} and term: {term}')\n",
    "    print(f'Levenshtein edit distance is {edit_d}')\n",
    "    print('The complete edit distance matrix is depicted below')\n",
    "    print(edit_m)\n",
    "    print('-' * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine distance and similarity\n",
    "\n",
    "The cosine distance is a metric that can be actually derived from the cosine similarity and vice versa. Considering we have two terms such that they are represented in their vectorized forms, Cosine similarity gives us the measure of the cosine of the angle between them when they are represented as non-zero positive vectors in an inner product space.\n",
    "\n",
    "Term vectors having similar orientation will have scores closer to 1 (cos 0) indicating the vectors are very close to each other in the same direction (near to zero degree angle between them). Term vectors having a similarity score close to 0 (cos 90) indicate unrelated terms with a near orthogonal angle between them. Term vectors with a similarity score close to -1 (cos 180) indicate terms that are completely oppositely oriented to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance(u, v):\n",
    "    distance = 1.0 - (np.dot(u, v) / \n",
    "                      (np.sqrt(sum(np.square(u))) * np.sqrt(sum(np.square(v))))\n",
    "                     )\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing similarity between root: Believe and term: beleive\n",
      "Cosine distance is -0.0\n",
      "Cosine similarity is 1.0\n",
      "----------------------------------------\n",
      "Analyzing similarity between root: Believe and term: bargain\n",
      "Cosine distance is 0.82\n",
      "Cosine similarity is 0.18000000000000005\n",
      "----------------------------------------\n",
      "Analyzing similarity between root: Believe and term: Elephant\n",
      "Cosine distance is 0.39\n",
      "Cosine similarity is 0.61\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for term, boc_term in zip(terms, boc_vector_terms):\n",
    "    print('Analyzing similarity between root: {} and term: {}'.format(root_term, term))\n",
    "    distance = round(cosine_distance(root_boc_vector, boc_term), 2)\n",
    "    similarity = 1 - distance\n",
    "    print(f'Cosine distance is {distance}')\n",
    "    print(f'Cosine similarity is {similarity}')\n",
    "    print('-' * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing document similarity\n",
    "\n",
    "Metrics:\n",
    "- cosine similarity\n",
    "- hellinger-bhattacharya distance\n",
    "- okapi bm25 ranking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.utils import normalize_corpus, build_feature_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the toy corpus index.\n",
    "toy_corpus = [\n",
    "    'The sky is blue',\n",
    "    'The sky is blue and beautiful',\n",
    "    'Look at the bright blue sky!',\n",
    "    'Python is a great programming language',\n",
    "    'Python and Java are popular Programming languages',\n",
    "    'Among Programming languages, both Python and Java are the most used in Analytics',\n",
    "    'The fox is quicker than the lazy dog',\n",
    "    'The dog is smarter than the fox',\n",
    "    'The dog, fox and cat are good friends'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the docs for which we will be measuring similarities.\n",
    "query_docs = ['The fox is definitely smarter than the dog',\n",
    "              'Java is a static typed programming language unlike Python',\n",
    "              'I love to relax under the beautiful blue sky!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normlaize\n"
     ]
    }
   ],
   "source": [
    "# Normalize and extract features from the toy corpus.\n",
    "norm_corpus = normalize_corpus(toy_corpus, lemmatize=True)\n",
    "tfidf_vectorizer, tfidf_features = build_feature_matrix(norm_corpus, \n",
    "                                                        feature_type='tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normlaize\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<3x22 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 10 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize and extract features from the query corpys.\n",
    "norm_query_docs = normalize_corpus(query_docs, lemmatize=True)\n",
    "query_docs_tfidf = tfidf_vectorizer.transform(norm_query_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(doc_features, corpus_features,\n",
    "                              top_n=3):\n",
    "    # Get document vectors.\n",
    "    doc_features = doc_features.toarray()[0]\n",
    "    corpus_features = corpus_features.toarray()\n",
    "    \n",
    "    # Compute similarities.\n",
    "    similarity = np.dot(doc_features,\n",
    "                        corpus_features.T)\n",
    "    \n",
    "    # Get doc with highest similarity scores.\n",
    "    top_docs = similarity.argsort()[::-1][:top_n]\n",
    "    top_docs_with_score = [(index, round(similarity[index], 3))\n",
    "                           for index in top_docs]\n",
    "    return top_docs_with_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document similarity analysis using cosine similarity\n",
      "============================================================\n",
      "Document 1: The fox is definitely smarter than the dog\n",
      "Top 2 similar docs:\n",
      "----------------------------------------\n",
      "Doc num: 8 Similarity score: 1.0\n",
      "Doc: The dog is smarter than the fox\n",
      "----------------------------------------\n",
      "Doc num: 7 Similarity score: 0.426\n",
      "Doc: The fox is quicker than the lazy dog\n",
      "----------------------------------------\n",
      "\n",
      "Document 2: Java is a static typed programming language unlike Python\n",
      "Top 2 similar docs:\n",
      "----------------------------------------\n",
      "Doc num: 5 Similarity score: 0.837\n",
      "Doc: Python and Java are popular Programming languages\n",
      "----------------------------------------\n",
      "Doc num: 6 Similarity score: 0.661\n",
      "Doc: Among Programming languages, both Python and Java are the most used in Analytics\n",
      "----------------------------------------\n",
      "\n",
      "Document 3: I love to relax under the beautiful blue sky!\n",
      "Top 2 similar docs:\n",
      "----------------------------------------\n",
      "Doc num: 2 Similarity score: 1.0\n",
      "Doc: The sky is blue and beautiful\n",
      "----------------------------------------\n",
      "Doc num: 1 Similarity score: 0.72\n",
      "Doc: The sky is blue\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get Cosine similarity results for our example documents.\n",
    "print('Document similarity analysis using cosine similarity')\n",
    "print('=' * 60)\n",
    "\n",
    "for index, doc in enumerate(query_docs):\n",
    "    doc_tfidf = query_docs_tfidf[index]\n",
    "    top_similar_docs = compute_cosine_similarity(doc_tfidf, \n",
    "                                                 tfidf_features,\n",
    "                                                 top_n=2)\n",
    "    \n",
    "    print(f'Document {index+1}: {doc}')\n",
    "    print(f'Top {len(top_similar_docs)} similar docs:')\n",
    "    print('-' * 40)\n",
    "    for doc_index, sim_score in top_similar_docs:\n",
    "        print(f'Doc num: {doc_index+1} Similarity score: {sim_score}\\nDoc: {toy_corpus[doc_index]}')\n",
    "        print('-' * 40)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hellinger-Bhattacharya Distance\n",
    "\n",
    "Aka Hellinger Distance or the Bhattacharya distance, is used to measure the similarity between two discrete or continuous probability distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hellinger_bhattacharya_distance(doc_features, corpus_features, top_n=3):\n",
    "    # Get document vectors.\n",
    "    doc_features = doc_features.toarray()[0]\n",
    "    corpus_features = corpus_features.toarray()\n",
    "    \n",
    "    # Compute hb distances.\n",
    "    distance = np.hstack(\n",
    "     np.sqrt(0.5 * np.sum(np.square(np.sqrt(doc_features) - np.sqrt(corpus_features)),\n",
    "                          axis=1)))\n",
    "    \n",
    "    # Get docs with the lowest distance scores.\n",
    "    top_docs = distance.argsort()[:top_n]\n",
    "    top_docs_with_scores = [(index, round(distance[index], 3))\n",
    "                             for index in top_docs]\n",
    "    return top_docs_with_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document similarity analysis using Hellinger-Bhattacharya distance:\n",
      "============================================================\n",
      "Document 1: The fox is definitely smarter than the dog\n",
      "Top 2 similar docs\n",
      "----------------------------------------\n",
      "Doc num: 8: Distance score: 0.0\n",
      "Doc: The dog is smarter than the fox\n",
      "----------------------------------------\n",
      "Doc num: 7: Distance score: 0.96\n",
      "Doc: The fox is quicker than the lazy dog\n",
      "----------------------------------------\n",
      "\n",
      "Document 2: Java is a static typed programming language unlike Python\n",
      "Top 2 similar docs\n",
      "----------------------------------------\n",
      "Doc num: 5: Distance score: 0.53\n",
      "Doc: Python and Java are popular Programming languages\n",
      "----------------------------------------\n",
      "Doc num: 4: Distance score: 0.766\n",
      "Doc: Python is a great programming language\n",
      "----------------------------------------\n",
      "\n",
      "Document 3: I love to relax under the beautiful blue sky!\n",
      "Top 2 similar docs\n",
      "----------------------------------------\n",
      "Doc num: 2: Distance score: 0.0\n",
      "Doc: The sky is blue and beautiful\n",
      "----------------------------------------\n",
      "Doc num: 1: Distance score: 0.602\n",
      "Doc: The sky is blue\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get Hellinger-Bhattacharya distance based similarities for our example documents.\n",
    "print('Document similarity analysis using Hellinger-Bhattacharya distance:')\n",
    "print('=' * 60)\n",
    "for index, doc in enumerate(query_docs):\n",
    "    doc_tfidf = query_docs_tfidf[index]\n",
    "    top_similar_docs = compute_hellinger_bhattacharya_distance(doc_tfidf, \n",
    "                                                               tfidf_features,\n",
    "                                                               top_n=2)\n",
    "    print(f'Document {index+1}: {doc}')\n",
    "    print(f'Top {len(top_similar_docs)} similar docs')\n",
    "    print('-' * 40)\n",
    "    for doc_index, sim_score in top_similar_docs:\n",
    "        print(f'Doc num: {doc_index+1}: Distance score: {sim_score}\\nDoc: {toy_corpus[doc_index]}')\n",
    "        print('-' * 40)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Okapi BM25 ranking\n",
    "\n",
    "BM stands for best matching. The Okapi BM25 can be formally defined as a document ranking and retrieval function based on a Bag-of-Words based model for retrieving relevant documents based on a user input query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "def compute_corpus_term_idfs(corpus_features, norm_corpus):\n",
    "    dfs = np.diff(sp.csc_matrix(corpus_features, copy=True).indptr)\n",
    "    dfs = 1 + dfs # To smoothen the idf later.\n",
    "    total_docs = 1 + len(norm_corpus)\n",
    "    idfs = 1.0 + np.log(float(total_docs) / dfs)\n",
    "    return idfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bm25_similarity(doc_features, corpus_features,\n",
    "                            corpus_doc_lengths, \n",
    "                            avg_doc_length,\n",
    "                            term_idfs, k1=1.5, b=0.75, top_n=3):\n",
    "    # Get corpus bag of words features.\n",
    "    corpus_features = corpus_features.toarray()\n",
    "    \n",
    "    # Convert query document features to binary features.\n",
    "    # This is to keep a note of which terms exist per document.\n",
    "    doc_features = doc_features.toarray()[0]\n",
    "    doc_features[doc_features >= 1] = 1\n",
    "    \n",
    "    # Compute the document idf scores for present terms.\n",
    "    doc_idfs = doc_features * term_idfs\n",
    "    \n",
    "    # Compute the numerator expression in BM25 equation.\n",
    "    numerator_coeff = corpus_features * (k1 + 1)\n",
    "    numerator = np.multiply(doc_idfs, numerator_coeff)\n",
    "    \n",
    "    # Compute denominator expression in BM25 equation.\n",
    "    denominator_coeff = k1 * (1 - b + (b * (corpus_doc_lengths / avg_doc_length)))\n",
    "    denominator_coeff = np.vstack(denominator_coeff)\n",
    "    denominator = corpus_features + denominator_coeff\n",
    "    \n",
    "    # Compute the BM25 score combining the above equations.\n",
    "    bm25_scores = np.sum(np.divide(numerator,\n",
    "                                   denominator),\n",
    "                         axis=1)\n",
    "    \n",
    "    # Get top n relevant docs with highest BM25 score.\n",
    "    top_docs = bm25_scores.argsort()[::-1][:top_n]\n",
    "    top_docs_with_score = [(index, round(bm25_scores[index], 3))\n",
    "                           for index in top_docs]\n",
    "    return top_docs_with_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document similarity analysis using BM25\n",
      "============================================================\n",
      "Document 1: The fox is definitely smarter than the dog\n",
      "Top 2 similar docs:\n",
      "----------------------------------------\n",
      "Doc num: 8 BM25 Score: 7.334\n",
      "Doc: The dog is smarter than the fox\n",
      "----------------------------------------\n",
      "Doc num: 7 BM25 Score: 3.88\n",
      "Doc: The fox is quicker than the lazy dog\n",
      "----------------------------------------\n",
      "\n",
      "Document 2: Java is a static typed programming language unlike Python\n",
      "Top 2 similar docs:\n",
      "----------------------------------------\n",
      "Doc num: 5 BM25 Score: 7.248\n",
      "Doc: Python and Java are popular Programming languages\n",
      "----------------------------------------\n",
      "Doc num: 6 BM25 Score: 6.042\n",
      "Doc: Among Programming languages, both Python and Java are the most used in Analytics\n",
      "----------------------------------------\n",
      "\n",
      "Document 3: I love to relax under the beautiful blue sky!\n",
      "Top 2 similar docs:\n",
      "----------------------------------------\n",
      "Doc num: 2 BM25 Score: 7.334\n",
      "Doc: The sky is blue and beautiful\n",
      "----------------------------------------\n",
      "Doc num: 1 BM25 Score: 4.984\n",
      "Doc: The sky is blue\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build bag of words based features first.\n",
    "vectorizer, corpus_features = build_feature_matrix(norm_corpus, feature_type='frequency')\n",
    "query_docs_features = vectorizer.transform(norm_query_docs)\n",
    "\n",
    "# Get average document length of the corpus (avgdl)\n",
    "docs_length = [len(doc.split()) for doc in norm_corpus]\n",
    "avg_dl = np.average(docs_length)\n",
    "\n",
    "# Get the corpus term idfs.\n",
    "corpus_term_idfs = compute_corpus_term_idfs(corpus_features, norm_corpus)\n",
    "\n",
    "# Analyze document similarity using BM25 framework.\n",
    "print('Document similarity analysis using BM25')\n",
    "print('=' * 60)\n",
    "\n",
    "for index, doc in enumerate(query_docs):\n",
    "    doc_features = query_docs_features[index]\n",
    "    top_similar_docs = compute_bm25_similarity(doc_features, \n",
    "                                               corpus_features,\n",
    "                                               docs_length,\n",
    "                                               avg_dl,\n",
    "                                               corpus_term_idfs,\n",
    "                                               k1=1.5, b=0.75,\n",
    "                                               top_n=2)\n",
    "    print(f'Document {index+1}: {doc}')\n",
    "    print(f'Top {len(top_similar_docs)} similar docs:')\n",
    "    print('-' * 40)\n",
    "    for doc_index, sim_score in top_similar_docs:\n",
    "        print(f'Doc num: {doc_index+1} BM25 Score: {sim_score}\\nDoc: {toy_corpus[doc_index]}')\n",
    "        print('-' * 40)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
